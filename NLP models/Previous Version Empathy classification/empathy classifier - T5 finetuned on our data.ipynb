{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "empathy classifier (T5 finetuned on our data, no prep)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a61a3d7a40244c48b24506c8b0353e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_022ef1b015264680ac3e93ccf0aca781",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e94b6f05135345f480fc0fe47c9dd2eb",
              "IPY_MODEL_28f6a7d24a5c4f519f17ae9667823eff",
              "IPY_MODEL_2ec2ed1266d34c62a7b794fc2e0fff41"
            ]
          }
        },
        "022ef1b015264680ac3e93ccf0aca781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e94b6f05135345f480fc0fe47c9dd2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35c9b02354824d708b11d2f06f6fc638",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5c4c0e3098a482da64ea408bed0558d"
          }
        },
        "28f6a7d24a5c4f519f17ae9667823eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df4dc20563914559966157ad45c92b00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f40fb6fbac5f4ec49b3e4d982e3eb0e3"
          }
        },
        "2ec2ed1266d34c62a7b794fc2e0fff41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ccbfb2c9c394ac6b7f1ef7c2e231aeb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:03&lt;00:00,  1.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75925700245f4e6988b416fb81f205f8"
          }
        },
        "35c9b02354824d708b11d2f06f6fc638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5c4c0e3098a482da64ea408bed0558d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df4dc20563914559966157ad45c92b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f40fb6fbac5f4ec49b3e4d982e3eb0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ccbfb2c9c394ac6b7f1ef7c2e231aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75925700245f4e6988b416fb81f205f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQVPHaNWjREG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4nE5R3iYSZ6"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers==2.9.0 \n",
        "!pip install pytorch_lightning==0.7.5\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwPxLDUiYk2V",
        "outputId": "127e8692-8d44-4d44-dded-6344f508564c"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import gc\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:PyTorch version 1.9.0+cu102 available.\n",
            "INFO:transformers.file_utils:TensorFlow version 2.6.0 available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPwpgLthZPZ1"
      },
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbxLyP7FZXCM"
      },
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "  def __init__(self, hparams):\n",
        "    super(T5FineTuner, self).__init__()\n",
        "    self.hparams = hparams\n",
        "    \n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "  \n",
        "  def is_logger(self):\n",
        "    return self.trainer.proc_rank <= 0\n",
        "  \n",
        "  def forward(\n",
        "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
        "  ):\n",
        "    return self.model(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        lm_labels=lm_labels,\n",
        "    )\n",
        "\n",
        "  def _step(self, batch):\n",
        "    lm_labels = batch[\"target_ids\"]\n",
        "    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"source_ids\"],\n",
        "        attention_mask=batch[\"source_mask\"],\n",
        "        lm_labels=lm_labels,\n",
        "        decoder_attention_mask=batch['target_mask']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "\n",
        "    tensorboard_logs = {\"train_loss\": loss}\n",
        "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "  \n",
        "  def training_epoch_end(self, outputs):\n",
        "    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "    return {\"val_loss\": loss}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": self.hparams.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    self.opt = optimizer\n",
        "    return [optimizer]\n",
        "  \n",
        "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
        "    if self.trainer.use_tpu:\n",
        "      xm.optimizer_step(optimizer)\n",
        "    else:\n",
        "      optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    self.lr_scheduler.step()\n",
        "  \n",
        "  def get_tqdm_dict(self):\n",
        "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "    return tqdm_dict\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"my_train\", args=self.hparams)\n",
        "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
        "    t_total = (\n",
        "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "        // self.hparams.gradient_accumulation_steps\n",
        "        * float(self.hparams.num_train_epochs)\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    self.lr_scheduler = scheduler\n",
        "    return dataloader\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"my_val\", args=self.hparams)\n",
        "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh7aHARRZmIA"
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Validation results *****\")\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "      # Log results\n",
        "      for key in sorted(metrics):\n",
        "        if key not in [\"log\", \"progress_bar\"]:\n",
        "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "  def on_test_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Test results *****\")\n",
        "\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "\n",
        "      # Log and save results to file\n",
        "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "      with open(output_test_results_file, \"w\") as writer:\n",
        "        for key in sorted(metrics):\n",
        "          if key not in [\"log\", \"progress_bar\"]:\n",
        "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-qppTPUZxtk",
        "outputId": "54a4ec5a-a612-4f77-fb49-26425551b124"
      },
      "source": [
        "#Load the tokenizer for the T5-base model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKOMYXEmPXsk",
        "outputId": "e89ac087-e84d-4ac1-cd48-3ef162389c6a"
      },
      "source": [
        "#Try out the tokenizer\n",
        "text = \"How are you feeling today?\"\n",
        "enc = tokenizer.encode_plus(text)\n",
        "print(enc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [571, 33, 25, 1829, 469, 58], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ1prjCpm2nj",
        "outputId": "6706dd9f-cf46-44c0-c0c9-7ba34083b721"
      },
      "source": [
        "#See how the labels are encoded\n",
        "labels = [\"no\", \"weak\", \"strong\"]\n",
        "for lab in labels:\n",
        "  print(tokenizer.encode(lab))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[150]\n",
            "[5676]\n",
            "[1101]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8yVebeaeaCC"
      },
      "source": [
        "class EmpathyDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
        "    self.path = os.path.join(data_dir, type_path + '.txt')\n",
        "\n",
        "    self.data_column = \"text\"\n",
        "    self.class_column = \"score\"\n",
        "    self.data = pd.read_csv(self.path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
        "                            engine=\"python\")\n",
        "    \n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    self._build()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "  \n",
        "  def _build(self):\n",
        "    for idx in range(len(self.data)):\n",
        "      input_, target = self.data.loc[idx, self.data_column], self.data.loc[idx, self.class_column]      \n",
        "      \n",
        "      input_ = input_ + ' </s>'\n",
        "      target = str(target) + \" </s>\"\n",
        "\n",
        "       # tokenize inputs\n",
        "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "          [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "       # tokenize targets\n",
        "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "          [target], max_length=2, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "      self.inputs.append(tokenized_inputs)\n",
        "      self.targets.append(tokenized_targets)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBGuYB6nJH4i"
      },
      "source": [
        "####finetune the model on the 1100 labelled samples from our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnPKESx5A4d"
      },
      "source": [
        "#recover the same dataset split as made in the baseline notebook\n",
        "train_path = \"drive/MyDrive/empathy_classifier_data/my_train.txt\"\n",
        "test_path = \"drive/MyDrive/empathy_classifier_data/my_test.txt\"\n",
        "val_path = \"drive/MyDrive/empathy_classifier_data/my_val.txt\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yju-0IQnpC8R"
      },
      "source": [
        "###Train the T5 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TToMqHlo7bA",
        "outputId": "ea84caae-68b2-4d61-f56c-4c146bba053c"
      },
      "source": [
        "#load the tokenizer for this model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTs5-TrVsVyz"
      },
      "source": [
        "dataset = EmpathyDataset(tokenizer, 'drive/MyDrive/empathy_classifier_data/', 'my_val', 512)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n12PBnSzschr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07b877d-f3ca-4ed8-ab22-b032580fcb68"
      },
      "source": [
        "#show a sample\n",
        "data = dataset[42]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sometimes people can be adversely affected when trying Protocol 6. Have you tried using Protocol 6 recently and found the experience distressing?\n",
            "weak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19txdH5cpqPa"
      },
      "source": [
        "#rubbish collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAY8A7Jgo7_Z"
      },
      "source": [
        "args_dict = dict(\n",
        "    data_dir=\"\", # path for data files\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-base',\n",
        "    tokenizer_name_or_path='t5-base',\n",
        "    max_seq_length=512,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=8,\n",
        "    eval_batch_size=8,\n",
        "    num_train_epochs=16,\n",
        "    gradient_accumulation_steps=2, \n",
        "    n_gpu=1,\n",
        "    early_stop_callback=False,\n",
        "    fp_16=False, \n",
        "    opt_level='O1',\n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jg1VUA5p0dT"
      },
      "source": [
        "args_dict.update({'data_dir': 'drive/MyDrive/empathy_classifier_data/', 'output_dir': 'drive/MyDrive/t5_empathy', 'num_train_epochs':16})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "#print(args_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWvn-NqKp3y0"
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeNdS3WZp6p1"
      },
      "source": [
        "def get_dataset(tokenizer, type_path, args):\n",
        "  return EmpathyDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p84WWt8Yp-wh"
      },
      "source": [
        "#create instance of model\n",
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nJ6uxC5qpPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ae616c-113f-484f-a396-7249d0519c56"
      },
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:GPU available: True, used: True\n",
            "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMW0Pk_irCib"
      },
      "source": [
        "#train loop\n",
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNVgz9zVaVBN",
        "outputId": "800bdd54-f434-4ac4-c3dd-b0f29f5a0ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#save model (uncomment to save)\n",
        "'''\n",
        "torch.save(model.state_dict(), 'drive/MyDrive/t5_empathy/T5empathy_chosen.pt')\n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntorch.save(model.state_dict(), 'drive/MyDrive/t5_empathy/T5empathy_chosen.pt')\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi3oAUejVFo3"
      },
      "source": [
        "#load the model (uncomment to load)\n",
        "'''\n",
        "device = torch.device('cuda:0')\n",
        "model = T5FineTuner(args)\n",
        "model.load_state_dict(torch.load('drive/MyDrive/t5_empathy/T5empathy_chosen.pt'))\n",
        "model.to(device)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta-dCRdKo0jn"
      },
      "source": [
        "##Test set evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXUfYg73r0vt"
      },
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOG7cSPVr4kK"
      },
      "source": [
        "dataset = EmpathyDataset(tokenizer, 'drive/MyDrive/empathy_classifier_data', 'my_test', 512)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXH2MFnCvGtJ"
      },
      "source": [
        "it = iter(loader)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0LY4ua1vKHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcd0885-28c8-4f3a-dd37-fa1e5ae41b72"
      },
      "source": [
        "batch = next(it)\n",
        "batch[\"source_ids\"].shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QCcyElfvTyZ"
      },
      "source": [
        "outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "dec = [tokenizer.decode(ids) for ids in outs]\n",
        "\n",
        "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
        "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd86TUoavXLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87d0722-382e-43e9-dc49-a841a29daa22"
      },
      "source": [
        "#print some predictions\n",
        "for i in range(32):\n",
        "    c = texts[i]\n",
        "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
        "    print(\"\\n\".join(lines))\n",
        "    print(\"\\nActual label: %s\" % targets[i])\n",
        "    print(\"predicted label: %s\" % dec[i])\n",
        "    print(\"=====================================================================\\n\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: That can sometimes happen, but there are more protocols here which might work better for you.\n",
            "Would you like to try another and see if it helps?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: I can see you're feeling anxious. Has something happened that has you feeling this way?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: In all honesty, do you think that you are always available to consider alternatives to your\n",
            "point of view?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Please select the one which you think is best suited for you.\n",
            "\n",
            "Actual label: no\n",
            "predicted label: no\n",
            "=====================================================================\n",
            "\n",
            "text: Did this happen because of a recent or distant situation?\n",
            "\n",
            "Actual label: no\n",
            "predicted label: no\n",
            "=====================================================================\n",
            "\n",
            "text: Can you let me know if you were recently working on Protocol 11 and it brought back some bad\n",
            "feelings from the past?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: I'm sorry you're not feeling great. Has anything happened to make you feel this way?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: I see, I am sorry to hear that. Do you feel like a different protocol might help?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: Now you have tried this protocol and reached the end, do you feel better or worse about your\n",
            "situation?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Thank you for sharing. I'd like to ask you some questions so I can understand a bit more.\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: It is important to understand how long you have been dealing with this issue. May I ask if\n",
            "this was a recent or distant event?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: Did this event happen recently or is it something that has been on your mind for some time?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Thank you again, that is helpful for me to understand. Could it be that you are trying to\n",
            "control or manipulate someone else into doing something that you want them to do?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: I have some recommendations for you. Please take a look and choose any protocol that you'd\n",
            "like to try.\n",
            "\n",
            "Actual label: no\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Ah, I see. Is this something that's happened recently or a while ago?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Have a read through the protocol, please take your time and go at your own pace, there's no\n",
            "rush. When you have completed it, press 'continue'.\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: Not every protocol works for everyone, and that's okay, I would recommend not giving up and\n",
            "trying again. Would you like to attempt another one together?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: Thanks, I appreciate your cooperation. See you again soon!\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Do you feel like someone needs your help?\n",
            "\n",
            "Actual label: no\n",
            "predicted label: no\n",
            "=====================================================================\n",
            "\n",
            "text: Do you think that sometimes you encourage people to behave the way you think they should?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Do you feel that your current emotion may have been caused by a specific event or events?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Do you find yourself always taking the blame when things go wrong?\n",
            "\n",
            "Actual label: no\n",
            "predicted label: no\n",
            "=====================================================================\n",
            "\n",
            "text: Thank you for sharing. I believe that you are  ⁇, am I correct in saying that?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Welcome back! How are you feeling after having taken the protocol?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: I'm sorry about that. Was this caused by a specific event/s?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Is there anything going on in your personal life that could be upsetting, have you fallen out\n",
            "with anyone close to you?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: I'm really pleased we managed to have this time together, I hope it helped you. You can come\n",
            "back whenever you feel like talking some more.\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: Have you already tried thinking over that again by doing Protocol 6, and if so how was that,\n",
            "did it reignite uncomfortable emotions?\n",
            "\n",
            "Actual label: no\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Do you think you might have, or desire, the power to influence someone else?\n",
            "\n",
            "Actual label: no\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: From what you've told me, it sounds like you're feeling  ⁇, is this right?\n",
            "\n",
            "Actual label: weak\n",
            "predicted label: weak\n",
            "=====================================================================\n",
            "\n",
            "text: Thank you for your answers so far. May I ask if you feel that you are undergoing a personal\n",
            "crisis right now, or if you are experiencing unmanageable interpersonal difficulties with those\n",
            "around you?\n",
            "\n",
            "Actual label: strong\n",
            "predicted label: strong\n",
            "=====================================================================\n",
            "\n",
            "text: Do you feel like you have let someone down?\n",
            "\n",
            "Actual label: no\n",
            "predicted label: no\n",
            "=====================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jci7f3gKOD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a61a3d7a40244c48b24506c8b0353e4d",
            "022ef1b015264680ac3e93ccf0aca781",
            "e94b6f05135345f480fc0fe47c9dd2eb",
            "28f6a7d24a5c4f519f17ae9667823eff",
            "2ec2ed1266d34c62a7b794fc2e0fff41",
            "35c9b02354824d708b11d2f06f6fc638",
            "a5c4c0e3098a482da64ea408bed0558d",
            "df4dc20563914559966157ad45c92b00",
            "f40fb6fbac5f4ec49b3e4d982e3eb0e3",
            "3ccbfb2c9c394ac6b7f1ef7c2e231aeb",
            "75925700245f4e6988b416fb81f205f8"
          ]
        },
        "outputId": "075bc1ee-37fd-41ed-d924-e3b7452358c3"
      },
      "source": [
        "dataset = EmpathyDataset(tokenizer, 'drive/MyDrive/empathy_classifier_data/', 'my_test', 512)\n",
        "loader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
        "model.model.eval()\n",
        "outputs = []\n",
        "targets = []\n",
        "for batch in tqdm(loader):\n",
        "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in outs]\n",
        "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
        "  \n",
        "  outputs.extend(dec)\n",
        "  targets.extend(target)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a61a3d7a40244c48b24506c8b0353e4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfsmFcc6MSPR"
      },
      "source": [
        "for i, out in enumerate(outputs):\n",
        "  if out not in labels:\n",
        "    print(i, 'detected invalid prediction')\n",
        "    del outputs[i]\n",
        "    del targets[i]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZEBunOJMWfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe83c3d-be85-4d1d-fcbe-bd7f5d361076"
      },
      "source": [
        "#other metrics\n",
        "print(metrics.classification_report(targets, outputs, digits=4))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no     0.8889    0.7742    0.8276        31\n",
            "      strong     0.8649    0.8205    0.8421        39\n",
            "        weak     0.7021    0.8049    0.7500        41\n",
            "\n",
            "    accuracy                         0.8018       111\n",
            "   macro avg     0.8186    0.7999    0.8066       111\n",
            "weighted avg     0.8115    0.8018    0.8040       111\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv8yPUAbCkVe"
      },
      "source": [
        "####Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8-_OJESMZt6"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7zGD1brMc5S"
      },
      "source": [
        "cm = metrics.confusion_matrix(targets, outputs)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OhYybzfDuhk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "d6fdd223-0d75-4fd3-c1e7-adc74c5bac2e"
      },
      "source": [
        "df_cm = pd.DataFrame(cm, index = [\"no\", \"strong\", \"weak\"], columns = [\"no\", \"strong\", \"weak\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d10238150>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}