{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Empathy classifier (RoBERTa - finetuned on our data, no prep )",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePwzeHuNh919"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2tokZqttmTA"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers tokenizers\n",
        "!pip install pytorch_lightning==1.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqRRWe4UuuIh"
      },
      "source": [
        "#package imports \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "from typing import List\n",
        "import logging\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "from functools import lru_cache\n",
        "from argparse import Namespace\n",
        "from packaging import version\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI0r_TmmzOsO"
      },
      "source": [
        "#we define the paths for train, val, test (change if desired to match location of splits created in baseline notebook)\n",
        "train_path = \"drive/MyDrive/empathy_classifier_data/my_train.txt\"\n",
        "test_path = \"drive/MyDrive/empathy_classifier_data/my_test.txt\"\n",
        "val_path = \"drive/MyDrive/empathy_classifier_data/my_val.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3EjfPCrz-eH"
      },
      "source": [
        "#create a dictionary which associates each string label to an integer value\n",
        "labels = [ \"no\", \"weak\", \"strong\"]\n",
        "label2int = dict(zip(labels, list(range(len(labels)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_whSBDujRiga"
      },
      "source": [
        "###Now we can start building a classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPbTd5lmuzQn"
      },
      "source": [
        "#we use RoBERTa base model\n",
        "\n",
        "#load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG5lOOAsVgvM"
      },
      "source": [
        "#load actual model\n",
        "model = AutoModelWithLMHead.from_pretrained('roberta-base')\n",
        "base_model = model.base_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO3uhWnx5Jlt"
      },
      "source": [
        "#now we need a custom classification head on top of the LM\n",
        "\n",
        "#note: the following code is partly adapted from Marcin Zablocki's tutorial 'custom classifier on top of bert-like language model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSUMm4Oq7nvR"
      },
      "source": [
        "Use Mish activiation function as it's the one proposed in the original tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCEDXLxq628O"
      },
      "source": [
        "#using Mish\n",
        "@torch.jit.script\n",
        "def mish(input):\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "  \n",
        "class Mish(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return mish(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VDRSRsc71H2"
      },
      "source": [
        "#define an EmpathyClassificationModel class to do the actual fine-tuning\n",
        "\n",
        "class EmpathyClassificationModel(nn.Module):\n",
        "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, base_model_output_size),\n",
        "            Mish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, n_classes)\n",
        "        )\n",
        "        \n",
        "        for layer in self.classifier:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
        "                if layer.bias is not None:\n",
        "                    layer.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input_, *args):\n",
        "        X, attention_mask = input_\n",
        "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
        "        \n",
        "        return self.classifier(hidden_states[0][:, 0, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-N7WSY7Cb7v"
      },
      "source": [
        "Now some dataset preparation for the fine-tuning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDWkjaLV-5tj"
      },
      "source": [
        "!mkdir -p tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMMm5Ye1Db-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601535d6-10d6-4ad5-e4c5-e5374348bc56"
      },
      "source": [
        "#load pretrained tokenizer information\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.json',\n",
              " 'tokenizer/merges.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FVtbmrzDkF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a8efea-863e-4f03-fc8e-a127c0af7916"
      },
      "source": [
        "!ls tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "merges.txt\t\t tokenizer_config.json\tvocab.json\n",
            "special_tokens_map.json  tokenizer.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCLBZsMDn4s"
      },
      "source": [
        "#implementation of CollateFN to do tokenization and batches of sequences\n",
        "\n",
        "class TokenizersCollateFn:\n",
        "    def __init__(self, max_tokens=512): \n",
        "\n",
        "        #RoBERTa uses the BPE tokenizer, similarly to GPT-2\n",
        "        t = ByteLevelBPETokenizer(\n",
        "            \"tokenizer/vocab.json\",\n",
        "            \"tokenizer/merges.txt\"\n",
        "        )\n",
        "        t._tokenizer.post_processor = BertProcessing(\n",
        "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
        "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
        "        )\n",
        "        t.enable_truncation(max_tokens)\n",
        "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
        "        self.tokenizer = t\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
        "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
        "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
        "        labels = torch.tensor([x[1] for x in batch])\n",
        "        \n",
        "        return (sequences_padded, attention_masks_padded), labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktr6xeMuISin"
      },
      "source": [
        "#class to create dataset objects from the data\n",
        "\n",
        "class EmpathyDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        super().__init__()\n",
        "        self.data_column = \"text\"\n",
        "        self.class_column = \"class\"\n",
        "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
        "                               engine=\"python\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGWw4wGEJGhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf1b0f7-5d7c-460c-b933-059aeba26321"
      },
      "source": [
        "#sanity check, visualise one sample and label (converted to numerical)\n",
        "ds = EmpathyDataset(train_path)\n",
        "ds[20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Would you say that someone else caused you to feel this way?', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJHhNRcZK7sV"
      },
      "source": [
        "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
        "\n",
        "class TrainingModule(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.model = EmpathyClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels))\n",
        "        self.loss = nn.CrossEntropyLoss() #cross entropy loss since this is multi-class classification\n",
        "        self.save_hyperparameters(hparams)\n",
        "\n",
        "    def step(self, batch, step_name=\"train\"):\n",
        "        X, y = batch\n",
        "        loss = self.loss(self.forward(X), y)\n",
        "        loss_key = f\"{step_name}_loss\"\n",
        "        tensorboard_logs = {loss_key: loss}\n",
        "\n",
        "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
        "               \"progress_bar\": {loss_key: loss}}\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        return self.model(X, *args)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, \"train\")\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, \"val\")\n",
        "\n",
        "    def validation_end(self, outputs: List[dict]):\n",
        "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        return {\"val_loss\": loss}\n",
        "        \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.step(batch, \"test\")\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.create_data_loader(self.hparams.val_path)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.create_data_loader(self.hparams.test_path)\n",
        "                \n",
        "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
        "        return DataLoader(\n",
        "                    EmpathyDataset(ds_path),\n",
        "                    batch_size=self.hparams.batch_size,\n",
        "                    num_workers=4,\n",
        "                    shuffle=shuffle,\n",
        "                    collate_fn=TokenizersCollateFn()\n",
        "        )\n",
        "        \n",
        "    @lru_cache()\n",
        "    def total_steps(self):\n",
        "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
        "        lr_scheduler = get_linear_schedule_with_warmup(\n",
        "                    optimizer,\n",
        "                    num_warmup_steps=self.hparams.warmup_steps,\n",
        "                    num_training_steps=self.total_steps(),\n",
        "        )\n",
        "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
        "    \n",
        "    def save_model(self):\n",
        "        torch.save(self.model.state_dict(), 'drive/MyDrive/t5_empathy/RoBERTa_empathy_1ft.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3FiLr3LBrjs"
      },
      "source": [
        "#chosen hyperparams:\n",
        "hparams = Namespace(\n",
        "    train_path=train_path,\n",
        "    val_path=val_path,\n",
        "    test_path=test_path,\n",
        "    batch_size=16,\n",
        "    warmup_steps=100,\n",
        "    epochs=20,\n",
        "    lr=1.35E-05,\n",
        "    accumulate_grad_batches=1\n",
        ")\n",
        "module = TrainingModule(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Jv_U25B37g"
      },
      "source": [
        "#rubbish collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk4OrTTm1WZD"
      },
      "source": [
        "####Now we can fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRnl4HXvB5-T"
      },
      "source": [
        "#train\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
        "                     accumulate_grad_batches=hparams.accumulate_grad_batches)\n",
        "\n",
        "trainer.fit(module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqRa9Naja4Lu"
      },
      "source": [
        "#save model (uncomment to save)\n",
        "'''\n",
        "module.save_model()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bs2Y7aky4QS"
      },
      "source": [
        "##Evaluation on the held-out test\n",
        "This is a multi-class classification task for which we used cross-entropy loss. We will evaluate using accuracy, precision, recall, F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrAoUr9r2CYs",
        "outputId": "49f815be-dbd0-4ccf-894c-bac6c0560f85"
      },
      "source": [
        "with torch.no_grad():\n",
        "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
        "    module.eval().cuda()\n",
        "    true_y, pred_y = [], []\n",
        "    for i, batch_ in enumerate(module.test_dataloader()):\n",
        "        (X, attn), y = batch_\n",
        "        batch = (X.cuda(), attn.cuda())\n",
        "        print(progress[i % len(progress)], end=\"\\r\")\n",
        "        y_pred = torch.argmax(module(batch), dim=1)\n",
        "        true_y.extend(y.cpu())\n",
        "        pred_y.extend(y_pred.cpu())\n",
        "print(\"\\n\" + \"_\" * 80)\n",
        "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "________________________________________________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no     0.8571    0.7742    0.8136        31\n",
            "        weak     0.6364    0.6829    0.6588        41\n",
            "      strong     0.7692    0.7692    0.7692        39\n",
            "\n",
            "    accuracy                         0.7387       111\n",
            "   macro avg     0.7542    0.7421    0.7472       111\n",
            "weighted avg     0.7447    0.7387    0.7408       111\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "JGIQPsgl77xJ",
        "outputId": "3b8e0645-66e3-4ae8-f260-02fc70965c2a"
      },
      "source": [
        "#plot confusion matrix\n",
        "\n",
        "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
        "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
        "\n",
        "plt.rcParams.update({'font.size': 12}) \n",
        "plt.figure(figsize = (10,8));\n",
        "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flDHzToXs6T7"
      },
      "source": [
        "model = EmpathyClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels))\n",
        "model.load_state_dict(torch.load('drive/MyDrive/t5_empathy/RoBERTa_empathy_1ft.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IATvWSUuaPzC"
      },
      "source": [
        "import re\n",
        "\n",
        "def get_empathy_score(text):\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  text = text.lower()\n",
        "\n",
        "  t = ByteLevelBPETokenizer(\n",
        "            \"tokenizer/vocab.json\",\n",
        "            \"tokenizer/merges.txt\"\n",
        "        )\n",
        "  t._tokenizer.post_processor = BertProcessing(\n",
        "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
        "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
        "        )\n",
        "  t.enable_truncation(512)\n",
        "  t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
        "  tokenizer = t\n",
        "\n",
        "  encoded = tokenizer.encode(text)\n",
        "  sequence_padded = torch.tensor(encoded.ids).unsqueeze(0)\n",
        "  attention_mask_padded = torch.tensor(encoded.attention_mask).unsqueeze(0)\n",
        "   \n",
        "  output = model((sequence_padded, attention_mask_padded))\n",
        "  top_p, top_class = output.topk(1, dim=1)\n",
        "  label = int(top_class[0][0])\n",
        "  label_map = {v: k for k, v in label2int.items()}\n",
        "  \n",
        "  return label_map[label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VbK-RDw3su7V",
        "outputId": "1cf226c7-da85-4549-83e7-3e99516850d5"
      },
      "source": [
        "get_empathy_score('I can feel your pain and would like to help you feel better. Could you tell me if anything recent triggered this feeling?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'strong'"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}